{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12907041,"sourceType":"datasetVersion","datasetId":8166839},{"sourceId":12907645,"sourceType":"datasetVersion","datasetId":8167254},{"sourceId":12907651,"sourceType":"datasetVersion","datasetId":8167259},{"sourceId":13101869,"sourceType":"datasetVersion","datasetId":8299391},{"sourceId":13102136,"sourceType":"datasetVersion","datasetId":8299576}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Assessing the Impact of Question Ambiguity in Question-Answering Systems\n\n**Objective:** Evaluate how effectively LLMs detect and handle ambiguity in questions and analyze the impact on system performance and output uncertainty.","metadata":{}},{"cell_type":"markdown","source":"# STEP 4: Model Evaluation with [CLS] Token Masking\n\n- Perform the same precedure as in STEP 3, but with masking special token during answer prediction.","metadata":{}},{"cell_type":"code","source":"# Import libraries\n\n!pip install evaluate\n\nimport torch, evaluate, pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nfrom tqdm import tqdm\n\nimport pandas as pd\nimport evaluate\nimport string\nimport torch\nimport re\nimport ast\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:19:37.477338Z","iopub.execute_input":"2025-09-18T19:19:37.477519Z","iopub.status.idle":"2025-09-18T19:20:16.202603Z","shell.execute_reply.started":"2025-09-18T19:19:37.477494Z","shell.execute_reply":"2025-09-18T19:20:16.201762Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.4)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.5.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.6 fsspec-2025.3.0\n","output_type":"stream"},{"name":"stderr","text":"2025-09-18 19:19:59.232230: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758223199.456893      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758223199.513927      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"<div style=\"position:relative;padding:.75rem 1.25rem;margin-bottom:1rem;border:1px solid transparent;border-radius:.25rem;background-color:#dae8fc;border-color:#6c8ebf;color:#0c5460\">\n<b>Step 1: Load the Dataset</b> \n</div>\n\n- As input, use the same dataset as in STEP 3.","metadata":{}},{"cell_type":"code","source":"# Load the dataset\ndf = pd.read_csv(\"data/dataset_for_evaluation_task_3.csv\", sep=\";\")\nlen(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:26:14.634830Z","iopub.execute_input":"2025-09-18T19:26:14.635182Z","iopub.status.idle":"2025-09-18T19:26:14.669319Z","shell.execute_reply.started":"2025-09-18T19:26:14.635158Z","shell.execute_reply":"2025-09-18T19:26:14.668606Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"1265"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:26:39.998785Z","iopub.execute_input":"2025-09-18T19:26:39.999109Z","iopub.status.idle":"2025-09-18T19:26:40.022876Z","shell.execute_reply.started":"2025-09-18T19:26:39.999088Z","shell.execute_reply":"2025-09-18T19:26:40.022348Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                             context target_word  \\\n0  Beyoncé's first solo recording was a feature o...       album   \n1  Following the disbandment of Destiny's Child i...       album   \n2  Beyoncé's first solo recording was a feature o...       album   \n3  Beyoncé's first solo recording was a feature o...       album   \n4  In November 2003, she embarked on the Dangerou...       album   \n\n                                            question  \\\n0  The album, Dangerously in Love achieved what s...   \n1  After her second solo album, what other entert...   \n2  Beyonce's first album by herself was called what?   \n3  Beyonce's first solo album in the U.S. with wh...   \n4      Destiny's Child's final album was named what?   \n\n                                  annotated_question  \\\n0                   What spot did the album achieve?   \n1  After her second album, what other entertainme...   \n2                   Her first album was called what?   \n3  Her first album in the U.S. featured which art...   \n4                  Their final album was named what?   \n\n                                             answers  \n0   {'text': ['number four'], 'answer_start': [123]}  \n1        {'text': ['acting'], 'answer_start': [207]}  \n2  {'text': ['Dangerously in Love'], 'answer_star...  \n3          {'text': ['Jay Z'], 'answer_start': [48]}  \n4  {'text': ['Destiny Fulfilled'], 'answer_start'...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>context</th>\n      <th>target_word</th>\n      <th>question</th>\n      <th>annotated_question</th>\n      <th>answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Beyoncé's first solo recording was a feature o...</td>\n      <td>album</td>\n      <td>The album, Dangerously in Love achieved what s...</td>\n      <td>What spot did the album achieve?</td>\n      <td>{'text': ['number four'], 'answer_start': [123]}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Following the disbandment of Destiny's Child i...</td>\n      <td>album</td>\n      <td>After her second solo album, what other entert...</td>\n      <td>After her second album, what other entertainme...</td>\n      <td>{'text': ['acting'], 'answer_start': [207]}</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Beyoncé's first solo recording was a feature o...</td>\n      <td>album</td>\n      <td>Beyonce's first album by herself was called what?</td>\n      <td>Her first album was called what?</td>\n      <td>{'text': ['Dangerously in Love'], 'answer_star...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Beyoncé's first solo recording was a feature o...</td>\n      <td>album</td>\n      <td>Beyonce's first solo album in the U.S. with wh...</td>\n      <td>Her first album in the U.S. featured which art...</td>\n      <td>{'text': ['Jay Z'], 'answer_start': [48]}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>In November 2003, she embarked on the Dangerou...</td>\n      <td>album</td>\n      <td>Destiny's Child's final album was named what?</td>\n      <td>Their final album was named what?</td>\n      <td>{'text': ['Destiny Fulfilled'], 'answer_start'...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"<div style=\"position:relative;padding:.75rem 1.25rem;margin-bottom:1rem;border:1px solid transparent;border-radius:.25rem;background-color:#dae8fc;border-color:#6c8ebf;color:#0c5460\">\n<b>Step 2: Data Normalization</b> \n</div>\n\nDefine functions:\n- parse_answer() – parses dictionaries.\n- extract_answer_text() – extracts and normalizes the correct answer text.\n  \nApply normalization to all relevant text fields: context, question, annotated_question, and answers.\n\nSource for code:\n\n- *[ast.literal_eval](https://docs.python.org/3/library/ast.html#ast.literal_eval)*","metadata":{}},{"cell_type":"code","source":"def parse_answer(value):\n    \"\"\"Convert stringified dicts into Python dictionaries.\"\"\"\n    if isinstance(value, str) and value.strip().startswith(\"{\") and \"'text'\" in value:\n        try:\n            return ast.literal_eval(value)\n        except:\n            return value  \n    return value\n\n\ndef extract_answer_text(x):\n    \"\"\"Extract raw answer text (no normalization), whether it's a dict, string, or number.\"\"\"\n    if isinstance(x, dict) and 'text' in x:\n        return str(x['text'])\n    elif isinstance(x, (int, float)):\n        return str(x)\n    elif isinstance(x, str):\n        return x\n    else:\n        return \"\"\n\n\n# Parse answers\ndf['answers'] = df['answers'].apply(parse_answer)\n\n# Extract raw text\ndf['ground_truth_answer'] = df['answers'].apply(extract_answer_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:27:04.922504Z","iopub.execute_input":"2025-09-18T19:27:04.923267Z","iopub.status.idle":"2025-09-18T19:27:04.954232Z","shell.execute_reply.started":"2025-09-18T19:27:04.923241Z","shell.execute_reply":"2025-09-18T19:27:04.953490Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"df[['answers', 'ground_truth_answer']].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:27:08.708373Z","iopub.execute_input":"2025-09-18T19:27:08.709098Z","iopub.status.idle":"2025-09-18T19:27:08.726313Z","shell.execute_reply.started":"2025-09-18T19:27:08.709065Z","shell.execute_reply":"2025-09-18T19:27:08.725545Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                                             answers      ground_truth_answer\n0   {'text': ['number four'], 'answer_start': [123]}          ['number four']\n1        {'text': ['acting'], 'answer_start': [207]}               ['acting']\n2  {'text': ['Dangerously in Love'], 'answer_star...  ['Dangerously in Love']\n3          {'text': ['Jay Z'], 'answer_start': [48]}                ['Jay Z']\n4  {'text': ['Destiny Fulfilled'], 'answer_start'...    ['Destiny Fulfilled']","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>answers</th>\n      <th>ground_truth_answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{'text': ['number four'], 'answer_start': [123]}</td>\n      <td>['number four']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'text': ['acting'], 'answer_start': [207]}</td>\n      <td>['acting']</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'text': ['Dangerously in Love'], 'answer_star...</td>\n      <td>['Dangerously in Love']</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'text': ['Jay Z'], 'answer_start': [48]}</td>\n      <td>['Jay Z']</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'text': ['Destiny Fulfilled'], 'answer_start'...</td>\n      <td>['Destiny Fulfilled']</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"## Load Model and Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForQuestionAnswering\nfrom transformers import BertTokenizer, BertForQuestionAnswering\nfrom transformers import RobertaTokenizer, RobertaForQuestionAnswering","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:27:14.358458Z","iopub.execute_input":"2025-09-18T19:27:14.358759Z","iopub.status.idle":"2025-09-18T19:27:14.429676Z","shell.execute_reply.started":"2025-09-18T19:27:14.358737Z","shell.execute_reply":"2025-09-18T19:27:14.429069Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"<div style=\"position:relative;padding:.75rem 1.25rem;margin-bottom:1rem;border:1px solid transparent;border-radius:.25rem;background-color:#dae8fc;border-color:#6c8ebf;color:#0c5460\">\n<b>Step 1: Connect to GPU</b> \n</div>","metadata":{}},{"cell_type":"code","source":"# Connect to GPU (if available)\n\nif torch.cuda.is_available():       \n    device = torch.device(\"cuda\")\n    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n    print('Device name:', torch.cuda.get_device_name(0))\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:27:16.398981Z","iopub.execute_input":"2025-09-18T19:27:16.399762Z","iopub.status.idle":"2025-09-18T19:27:16.404123Z","shell.execute_reply.started":"2025-09-18T19:27:16.399737Z","shell.execute_reply":"2025-09-18T19:27:16.403449Z"}},"outputs":[{"name":"stdout","text":"There are 1 GPU(s) available.\nDevice name: Tesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"<div style=\"position:relative;padding:.75rem 1.25rem;margin-bottom:1rem;border:1px solid transparent;border-radius:.25rem;background-color:#dae8fc;border-color:#6c8ebf;color:#0c5460\">\n<b>Step 2: Define Models and Tokenizers</b> \n</div>","metadata":{}},{"cell_type":"code","source":"# BERT\nbert_base_tokenizer = AutoTokenizer.from_pretrained(\"twmkn9/bert-base-uncased-squad2\")\nbert_base_model = AutoModelForQuestionAnswering.from_pretrained(\"twmkn9/bert-base-uncased-squad2\").to(device)\n\nbert_large_tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\nbert_large_model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad').to(device)\n\n\n# RoBERTa\nroberta_base_tokenizer = RobertaTokenizer.from_pretrained('deepset/roberta-base-squad2')\nroberta_base_model = RobertaForQuestionAnswering.from_pretrained('deepset/roberta-base-squad2').to(device)\n\nroberta_large_tokenizer = RobertaTokenizer.from_pretrained('deepset/roberta-large-squad2')\nroberta_large_model = RobertaForQuestionAnswering.from_pretrained('deepset/roberta-large-squad2').to(device)\n\n\n# DeBERTa\ndeberta_base_tokenizer = AutoTokenizer.from_pretrained(\"deepset/deberta-v3-base-squad2\")\ndeberta_base_model = AutoModelForQuestionAnswering.from_pretrained(\"deepset/deberta-v3-base-squad2\").to(device)\n\ndeberta_large_tokenizer = AutoTokenizer.from_pretrained(\"deepset/deberta-v3-large-squad2\")\ndeberta_large_model = AutoModelForQuestionAnswering.from_pretrained(\"deepset/deberta-v3-large-squad2\").to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:27:20.154786Z","iopub.execute_input":"2025-09-18T19:27:20.155089Z","iopub.status.idle":"2025-09-18T19:28:16.219605Z","shell.execute_reply.started":"2025-09-18T19:27:20.155062Z","shell.execute_reply":"2025-09-18T19:28:16.218487Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74762ede92434222bfabbea0fc769b1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/465 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b87950e404df4143af3dd2df84832b8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"570118aa9cbe42689d983e62a7583088"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f55c40bf49004f8fb86714c38c003c14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"734f8d7d404a49b2978613af619da1d4"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at twmkn9/bert-base-uncased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a12d0ed4433d4dbeb0e1ce416f34c2ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c1772d5d2e54312b0ebf339b351eaf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22ce5b890da14299b90e9c22030a70fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"076b1b4ab77e4111a6f87a3c720a1cce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b971385f320144b2b61ddb89b937e998"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2101a915d8484e7da9d72ab4e186a9db"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca666d868b744761a132c009ffe56024"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58aa62eaeee34d80a3c337b21714efc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49f370eab42c42c7823f988809840a61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a99d9b99494441eaad05c10a1bb9ec2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a30270af639486d9e6b80c5be0aaa46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cafca08db9f34e3b8ae52c95e6993531"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb5a7af1fa3c40dfbb655b3f9e294f86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c753023e3384bc8a6594785e9ca70d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8456eb094cad4fff902aff71f01d2ce0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7b8d04e12bf446c8ac22060dffab101"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/696 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98b5a83a57744c93a494ba9d925cc573"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"215ae14aa9aa4e14a6b6a76395daad04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/379 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"307faf8168aa4790bd6d2fcbd2bf86f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e94b6b29b9d42a2963177d41f85bd63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/8.65M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d40392c9683449649b764b9eb970bcd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62b4d925fb2e479daa18dad9fe2f3829"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1643547d726b4648ac528aa96edbc31a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/992 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18c329353b004cc9b40b3371ef24d8b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/735M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"064da46a4ac847368a8b998156108d7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/392 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8da1c0c780ee45908003a1839f68f540"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a81643326c1847a49a0b183ab6da7eff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/8.65M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84218a471f9c469c8fc9f4111e8cf783"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/18.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ff30d55882340269a5c8d5b2f3b384d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a147c1f07b694252ab6e6a89aff0bfc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f3e862388684c86bbcc013512d5a86d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7752f680e4945d488b6bf927ee2f80a"}},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# Define a dictionary\nmodels = {\n    \"bert-base\": (bert_base_tokenizer, bert_base_model),\n    \"bert-large\": (bert_large_tokenizer, bert_large_model),\n    \"roberta-base\": (roberta_base_tokenizer, roberta_base_model),\n    \"roberta-large\": (roberta_large_tokenizer, roberta_large_model),\n    \"deberta-base\": (deberta_base_tokenizer, deberta_base_model),\n    \"deberta-large\": (deberta_large_tokenizer, deberta_large_model)\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:28:31.907312Z","iopub.execute_input":"2025-09-18T19:28:31.908163Z","iopub.status.idle":"2025-09-18T19:28:31.912175Z","shell.execute_reply.started":"2025-09-18T19:28:31.908123Z","shell.execute_reply":"2025-09-18T19:28:31.911319Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## Answer Prediction","metadata":{}},{"cell_type":"markdown","source":"<div style=\"position:relative;padding:.75rem 1.25rem;margin-bottom:1rem;border:1px solid transparent;border-radius:.25rem;background-color:#dae8fc;border-color:#6c8ebf;color:#0c5460\">\n<b>Step 1: Answer Prediction - MASKING [CLS]</b> \n</div>\n\nIterates through each row in the dataset. Predicts answers for both the original and ambiguous question. Normalizes predictions and stores them in two new columns: *pred_answer_orig* and *pred_answer_ambig*. \n\nSource for code:\n- [-float('inf')](https://stackoverflow.com/questions/34264710/what-is-the-point-of-floatinf-in-python)","metadata":{}},{"cell_type":"code","source":"# MASKING [CLS]\n\n# Predict answers for original and ambiguous questions for all models\n\n# Iterate through models\nfor model_name, (tokenizer, model) in models.items():\n    print(f\"\\n Predicting answers with: {model_name}...\")\n    \n    model.eval()  # model to evaluation mode\n\n    # Store answers \n    pred_answers_orig = []\n    pred_answers_ambig = []\n\n    # Iterate through each row in a dataset\n    for _, row in tqdm(df.iterrows(), total=len(df)):\n        context = row['context']\n        question_orig = row['question']\n        question_ambig = row['annotated_question']\n\n        # Encode input  for original question (question and context)\n        inputs = tokenizer.encode_plus(\n            question_orig,\n            context,\n            return_tensors='pt',\n            truncation=True, # ensures the input not longer that max_length\n            max_length=512 # max number of tokents\n        ) \n        \n        inputs = {k: v.to(device) for k, v in inputs.items()}\n        with torch.no_grad():\n            outputs = model(**inputs)\n            \n        # Make a copy of the logits, but not modify the output\n        start_logits = outputs.start_logits.clone()\n        end_logits = outputs.end_logits.clone()\n\n        # Make the value of the [cls] token smaller than any number\n        # Prevent model to predict [CLS] or <s> tokens\n        start_logits[0][0] = -float('inf')\n        end_logits[0][0] = -float('inf')\n\n        # Select start and end position of the prediction\n        start = torch.argmax(start_logits)\n        end = torch.argmax(end_logits) + 1\n        answer_orig = tokenizer.convert_tokens_to_string(\n            tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][start:end])\n        ) \n        pred_answers_orig.append(answer_orig)\n\n        \n        # Predict for ambiguous question\n        inputs = tokenizer.encode_plus(\n            question_ambig,\n            context,\n            return_tensors='pt',\n            truncation=True,\n            max_length=512\n        )\n        \n        inputs = {k: v.to(device) for k, v in inputs.items()}\n        with torch.no_grad():\n            outputs = model(**inputs)\n            \n        # Make a copy of the logits, but not modify the output\n        start_logits = outputs.start_logits.clone()\n        end_logits = outputs.end_logits.clone()\n\n        # Make the value of the [cls] token smaller than any number\n        # Prevent model to predict [CLS] or <s> tokens\n        start_logits[0][0] = -float('inf')\n        end_logits[0][0] = -float('inf')\n\n        # Select start and end position of the prediction\n        start = torch.argmax(start_logits)\n        end = torch.argmax(end_logits) + 1\n        answer_ambig = tokenizer.convert_tokens_to_string(\n            tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][start:end])\n        ) \n        pred_answers_ambig.append(answer_ambig)\n        \n\n    # Save predictions\n    df[f'{model_name}_pred_orig'] = pred_answers_orig\n    df[f'{model_name}_pred_ambig'] = pred_answers_ambig","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:29:59.421671Z","iopub.execute_input":"2025-09-18T19:29:59.422229Z","iopub.status.idle":"2025-09-18T19:36:13.996689Z","shell.execute_reply.started":"2025-09-18T19:29:59.422203Z","shell.execute_reply":"2025-09-18T19:36:13.995964Z"}},"outputs":[{"name":"stdout","text":"\n Predicting answers with: bert-base...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1265/1265 [00:27<00:00, 45.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Predicting answers with: bert-large...\n","output_type":"stream"},{"name":"stderr","text":"  9%|▉         | 114/1265 [00:07<01:06, 17.20it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\nBe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 1265/1265 [01:13<00:00, 17.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Predicting answers with: roberta-base...\n","output_type":"stream"},{"name":"stderr","text":"  9%|▉         | 112/1265 [00:02<00:27, 41.82it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\nBe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 1265/1265 [00:29<00:00, 42.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Predicting answers with: roberta-large...\n","output_type":"stream"},{"name":"stderr","text":"  9%|▉         | 114/1265 [00:06<01:05, 17.68it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\nBe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 1265/1265 [01:12<00:00, 17.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Predicting answers with: deberta-base...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1265/1265 [00:56<00:00, 22.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Predicting answers with: deberta-large...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1265/1265 [01:55<00:00, 10.98it/s]\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"df.to_csv(\"data/model_answer_predictions_no_cls_4.csv\", index=False)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:37:15.193245Z","iopub.execute_input":"2025-09-18T19:37:15.193959Z","iopub.status.idle":"2025-09-18T19:37:15.258358Z","shell.execute_reply.started":"2025-09-18T19:37:15.193932Z","shell.execute_reply":"2025-09-18T19:37:15.257765Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                             context target_word  \\\n0  Beyoncé's first solo recording was a feature o...       album   \n1  Following the disbandment of Destiny's Child i...       album   \n2  Beyoncé's first solo recording was a feature o...       album   \n3  Beyoncé's first solo recording was a feature o...       album   \n4  In November 2003, she embarked on the Dangerou...       album   \n\n                                            question  \\\n0  The album, Dangerously in Love achieved what s...   \n1  After her second solo album, what other entert...   \n2  Beyonce's first album by herself was called what?   \n3  Beyonce's first solo album in the U.S. with wh...   \n4      Destiny's Child's final album was named what?   \n\n                                  annotated_question  \\\n0                   What spot did the album achieve?   \n1  After her second album, what other entertainme...   \n2                   Her first album was called what?   \n3  Her first album in the U.S. featured which art...   \n4                  Their final album was named what?   \n\n                                             answers      ground_truth_answer  \\\n0   {'text': ['number four'], 'answer_start': [123]}          ['number four']   \n1        {'text': ['acting'], 'answer_start': [207]}               ['acting']   \n2  {'text': ['Dangerously in Love'], 'answer_star...  ['Dangerously in Love']   \n3          {'text': ['Jay Z'], 'answer_start': [48]}                ['Jay Z']   \n4  {'text': ['Destiny Fulfilled'], 'answer_start'...    ['Destiny Fulfilled']   \n\n   bert-base_pred_orig bert-base_pred_ambig bert-large_pred_orig  \\\n0          number four          number four          number four   \n1               acting               acting               acting   \n2  dangerously in love  dangerously in love  dangerously in love   \n3                jay z                jay z                jay z   \n4    destiny fulfilled    destiny fulfilled    destiny fulfilled   \n\n  bert-large_pred_ambig roberta-base_pred_orig  \\\n0                                         four   \n1                acting                 acting   \n2   dangerously in love    Dangerously in Love   \n3                 jay z                  Jay Z   \n4     destiny fulfilled      Destiny Fulfilled   \n\n                             roberta-base_pred_ambig roberta-large_pred_orig  \\\n0                                        number four                    four   \n1                                             acting                  acting   \n2                                Dangerously in Love     Dangerously in Love   \n3   Jay Z's \"'03 Bonnie & Clyde\" that was release...                   Jay Z   \n4                                  Destiny Fulfilled       Destiny Fulfilled   \n\n  roberta-large_pred_ambig deberta-base_pred_orig deberta-base_pred_ambig  \\\n0   atop the Billboard 200            number four                    four   \n1                   acting                 acting                  acting   \n2      Dangerously in Love    Dangerously in Love     Dangerously in Love   \n3                    Jay Z                  Jay Z                   Jay Z   \n4        Destiny Fulfilled      Destiny Fulfilled       Destiny Fulfilled   \n\n  deberta-large_pred_orig deberta-large_pred_ambig  \n0                    four   atop the Billboard 200  \n1                  acting                   acting  \n2     Dangerously in Love      Dangerously in Love  \n3                   Jay Z                    Jay Z  \n4       Destiny Fulfilled        Destiny Fulfilled  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>context</th>\n      <th>target_word</th>\n      <th>question</th>\n      <th>annotated_question</th>\n      <th>answers</th>\n      <th>ground_truth_answer</th>\n      <th>bert-base_pred_orig</th>\n      <th>bert-base_pred_ambig</th>\n      <th>bert-large_pred_orig</th>\n      <th>bert-large_pred_ambig</th>\n      <th>roberta-base_pred_orig</th>\n      <th>roberta-base_pred_ambig</th>\n      <th>roberta-large_pred_orig</th>\n      <th>roberta-large_pred_ambig</th>\n      <th>deberta-base_pred_orig</th>\n      <th>deberta-base_pred_ambig</th>\n      <th>deberta-large_pred_orig</th>\n      <th>deberta-large_pred_ambig</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Beyoncé's first solo recording was a feature o...</td>\n      <td>album</td>\n      <td>The album, Dangerously in Love achieved what s...</td>\n      <td>What spot did the album achieve?</td>\n      <td>{'text': ['number four'], 'answer_start': [123]}</td>\n      <td>['number four']</td>\n      <td>number four</td>\n      <td>number four</td>\n      <td>number four</td>\n      <td></td>\n      <td>four</td>\n      <td>number four</td>\n      <td>four</td>\n      <td>atop the Billboard 200</td>\n      <td>number four</td>\n      <td>four</td>\n      <td>four</td>\n      <td>atop the Billboard 200</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Following the disbandment of Destiny's Child i...</td>\n      <td>album</td>\n      <td>After her second solo album, what other entert...</td>\n      <td>After her second album, what other entertainme...</td>\n      <td>{'text': ['acting'], 'answer_start': [207]}</td>\n      <td>['acting']</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Beyoncé's first solo recording was a feature o...</td>\n      <td>album</td>\n      <td>Beyonce's first album by herself was called what?</td>\n      <td>Her first album was called what?</td>\n      <td>{'text': ['Dangerously in Love'], 'answer_star...</td>\n      <td>['Dangerously in Love']</td>\n      <td>dangerously in love</td>\n      <td>dangerously in love</td>\n      <td>dangerously in love</td>\n      <td>dangerously in love</td>\n      <td>Dangerously in Love</td>\n      <td>Dangerously in Love</td>\n      <td>Dangerously in Love</td>\n      <td>Dangerously in Love</td>\n      <td>Dangerously in Love</td>\n      <td>Dangerously in Love</td>\n      <td>Dangerously in Love</td>\n      <td>Dangerously in Love</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Beyoncé's first solo recording was a feature o...</td>\n      <td>album</td>\n      <td>Beyonce's first solo album in the U.S. with wh...</td>\n      <td>Her first album in the U.S. featured which art...</td>\n      <td>{'text': ['Jay Z'], 'answer_start': [48]}</td>\n      <td>['Jay Z']</td>\n      <td>jay z</td>\n      <td>jay z</td>\n      <td>jay z</td>\n      <td>jay z</td>\n      <td>Jay Z</td>\n      <td>Jay Z's \"'03 Bonnie &amp; Clyde\" that was release...</td>\n      <td>Jay Z</td>\n      <td>Jay Z</td>\n      <td>Jay Z</td>\n      <td>Jay Z</td>\n      <td>Jay Z</td>\n      <td>Jay Z</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>In November 2003, she embarked on the Dangerou...</td>\n      <td>album</td>\n      <td>Destiny's Child's final album was named what?</td>\n      <td>Their final album was named what?</td>\n      <td>{'text': ['Destiny Fulfilled'], 'answer_start'...</td>\n      <td>['Destiny Fulfilled']</td>\n      <td>destiny fulfilled</td>\n      <td>destiny fulfilled</td>\n      <td>destiny fulfilled</td>\n      <td>destiny fulfilled</td>\n      <td>Destiny Fulfilled</td>\n      <td>Destiny Fulfilled</td>\n      <td>Destiny Fulfilled</td>\n      <td>Destiny Fulfilled</td>\n      <td>Destiny Fulfilled</td>\n      <td>Destiny Fulfilled</td>\n      <td>Destiny Fulfilled</td>\n      <td>Destiny Fulfilled</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"<div style=\"position:relative;padding:.75rem 1.25rem;margin-bottom:1rem;border:1px solid transparent;border-radius:.25rem;background-color:#dae8fc;border-color:#6c8ebf;color:#0c5460\">\n<b>2. Save Answer Predictions fo Target Words used in Error Analysis</b> \n</div>","metadata":{}},{"cell_type":"code","source":"# Save words for error analysis\nwords = [\"cabinet\", \"cell\", \"fan\", \"season\"]\n\ndf_words_no_cls = df[df[\"target_word\"].isin(words)]\ndf_words_no_cls.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:37:36.515109Z","iopub.execute_input":"2025-09-18T19:37:36.515367Z","iopub.status.idle":"2025-09-18T19:37:36.540405Z","shell.execute_reply.started":"2025-09-18T19:37:36.515349Z","shell.execute_reply":"2025-09-18T19:37:36.539761Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"                                               context target_word  \\\n218  Legislative power lies with the Nitijela. The ...     cabinet   \n219  Preceding the reform law, in August 1952, comm...     cabinet   \n220  New Haven is the birthplace of former presiden...     cabinet   \n\n                                              question  \\\n218  How many ministers are in the Presidential Cab...   \n219  How many posts did the Muslim Brotherhood get ...   \n220  Serving in President Obama's cabinet, this man...   \n\n                                    annotated_question  \\\n218                How many people are in the cabinet?   \n219  How many roles did the group hold in the cabinet?   \n220  Serving in the cabinet, this individual also s...   \n\n                                             answers ground_truth_answer  \\\n218         {'text': ['ten'], 'answer_start': [250]}             ['ten']   \n219         {'text': ['two'], 'answer_start': [537]}             ['two']   \n220  {'text': ['John Kerry'], 'answer_start': [419]}      ['John Kerry']   \n\n    bert-base_pred_orig           bert-base_pred_ambig bert-large_pred_orig  \\\n218                 ten                            ten                  ten   \n219                 two                           four                        \n220          john kerry  secretary of state john kerry           john kerry   \n\n    bert-large_pred_ambig roberta-base_pred_orig roberta-base_pred_ambig  \\\n218                   ten                    ten                     ten   \n219                   two                   four                    four   \n220            john kerry             John Kerry              John Kerry   \n\n    roberta-large_pred_orig roberta-large_pred_ambig deberta-base_pred_orig  \\\n218                     ten                      ten                    ten   \n219                     two                      two                    two   \n220              John Kerry          Yale Law School             John Kerry   \n\n    deberta-base_pred_ambig deberta-large_pred_orig deberta-large_pred_ambig  \n218                     ten                     ten                      ten  \n219      two of its members                     two                      two  \n220              John Kerry              John Kerry               John Kerry  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>context</th>\n      <th>target_word</th>\n      <th>question</th>\n      <th>annotated_question</th>\n      <th>answers</th>\n      <th>ground_truth_answer</th>\n      <th>bert-base_pred_orig</th>\n      <th>bert-base_pred_ambig</th>\n      <th>bert-large_pred_orig</th>\n      <th>bert-large_pred_ambig</th>\n      <th>roberta-base_pred_orig</th>\n      <th>roberta-base_pred_ambig</th>\n      <th>roberta-large_pred_orig</th>\n      <th>roberta-large_pred_ambig</th>\n      <th>deberta-base_pred_orig</th>\n      <th>deberta-base_pred_ambig</th>\n      <th>deberta-large_pred_orig</th>\n      <th>deberta-large_pred_ambig</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>218</th>\n      <td>Legislative power lies with the Nitijela. The ...</td>\n      <td>cabinet</td>\n      <td>How many ministers are in the Presidential Cab...</td>\n      <td>How many people are in the cabinet?</td>\n      <td>{'text': ['ten'], 'answer_start': [250]}</td>\n      <td>['ten']</td>\n      <td>ten</td>\n      <td>ten</td>\n      <td>ten</td>\n      <td>ten</td>\n      <td>ten</td>\n      <td>ten</td>\n      <td>ten</td>\n      <td>ten</td>\n      <td>ten</td>\n      <td>ten</td>\n      <td>ten</td>\n      <td>ten</td>\n    </tr>\n    <tr>\n      <th>219</th>\n      <td>Preceding the reform law, in August 1952, comm...</td>\n      <td>cabinet</td>\n      <td>How many posts did the Muslim Brotherhood get ...</td>\n      <td>How many roles did the group hold in the cabinet?</td>\n      <td>{'text': ['two'], 'answer_start': [537]}</td>\n      <td>['two']</td>\n      <td>two</td>\n      <td>four</td>\n      <td></td>\n      <td>two</td>\n      <td>four</td>\n      <td>four</td>\n      <td>two</td>\n      <td>two</td>\n      <td>two</td>\n      <td>two of its members</td>\n      <td>two</td>\n      <td>two</td>\n    </tr>\n    <tr>\n      <th>220</th>\n      <td>New Haven is the birthplace of former presiden...</td>\n      <td>cabinet</td>\n      <td>Serving in President Obama's cabinet, this man...</td>\n      <td>Serving in the cabinet, this individual also s...</td>\n      <td>{'text': ['John Kerry'], 'answer_start': [419]}</td>\n      <td>['John Kerry']</td>\n      <td>john kerry</td>\n      <td>secretary of state john kerry</td>\n      <td>john kerry</td>\n      <td>john kerry</td>\n      <td>John Kerry</td>\n      <td>John Kerry</td>\n      <td>John Kerry</td>\n      <td>Yale Law School</td>\n      <td>John Kerry</td>\n      <td>John Kerry</td>\n      <td>John Kerry</td>\n      <td>John Kerry</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"df_words_no_cls.tail(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:37:47.548165Z","iopub.execute_input":"2025-09-18T19:37:47.548446Z","iopub.status.idle":"2025-09-18T19:37:47.562847Z","shell.execute_reply.started":"2025-09-18T19:37:47.548426Z","shell.execute_reply":"2025-09-18T19:37:47.561972Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                               context target_word  \\\n943  In season eight, Latin Grammy Award-nominated ...      season   \n944  The first season was co-hosted by Ryan Seacres...      season   \n945  Guest judges may occasionally be introduced. I...      season   \n\n                                              question  \\\n943  Who was added as a fourth judge in the eighth ...   \n944  Who was the only host of American Idol after s...   \n945           Who were the guest judges in season two?   \n\n                                    annotated_question  \\\n943  Who was brought in during the season for a fou...   \n944  Who hosted the show once season one had passed...   \n945  Who joined in as a guest during the second sea...   \n\n                                               answers  \\\n943  {'text': ['Kara DioGuardi'], 'answer_start': [...   \n944  {'text': ['Ryan Seacrest'], 'answer_start': [34]}   \n945  {'text': ['Lionel Richie and Robin Gibb'], 'an...   \n\n                  ground_truth_answer           bert-base_pred_orig  \\\n943                ['Kara DioGuardi']                kara dioguardi   \n944                 ['Ryan Seacrest']               brian dunkleman   \n945  ['Lionel Richie and Robin Gibb']  lionel richie and robin gibb   \n\n                bert-base_pred_ambig          bert-large_pred_orig  \\\n943                   kara dioguardi                kara dioguardi   \n944                  brian dunkleman                 ryan seacrest   \n945  donna summer, quentin tarantino  lionel richie and robin gibb   \n\n            bert-large_pred_ambig         roberta-base_pred_orig  \\\n943                kara dioguardi                 Kara DioGuardi   \n944                 ryan seacrest                Brian Dunkleman   \n945  lionel richie and robin gibb   Lionel Richie and Robin Gibb   \n\n           roberta-base_pred_ambig        roberta-large_pred_orig  \\\n943                 Kara DioGuardi                 Kara DioGuardi   \n944                  Ryan Seacrest                  Ryan Seacrest   \n945   Lionel Richie and Robin Gibb   Lionel Richie and Robin Gibb   \n\n          roberta-large_pred_ambig        deberta-base_pred_orig  \\\n943                 Kara DioGuardi                Kara DioGuardi   \n944                  Ryan Seacrest                 Ryan Seacrest   \n945   Lionel Richie and Robin Gibb  Lionel Richie and Robin Gibb   \n\n          deberta-base_pred_ambig       deberta-large_pred_orig  \\\n943                Kara DioGuardi                Kara DioGuardi   \n944                 Ryan Seacrest                 Ryan Seacrest   \n945  Lionel Richie and Robin Gibb  Lionel Richie and Robin Gibb   \n\n    deberta-large_pred_ambig  \n943           Kara DioGuardi  \n944            Ryan Seacrest  \n945            Lionel Richie  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>context</th>\n      <th>target_word</th>\n      <th>question</th>\n      <th>annotated_question</th>\n      <th>answers</th>\n      <th>ground_truth_answer</th>\n      <th>bert-base_pred_orig</th>\n      <th>bert-base_pred_ambig</th>\n      <th>bert-large_pred_orig</th>\n      <th>bert-large_pred_ambig</th>\n      <th>roberta-base_pred_orig</th>\n      <th>roberta-base_pred_ambig</th>\n      <th>roberta-large_pred_orig</th>\n      <th>roberta-large_pred_ambig</th>\n      <th>deberta-base_pred_orig</th>\n      <th>deberta-base_pred_ambig</th>\n      <th>deberta-large_pred_orig</th>\n      <th>deberta-large_pred_ambig</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>943</th>\n      <td>In season eight, Latin Grammy Award-nominated ...</td>\n      <td>season</td>\n      <td>Who was added as a fourth judge in the eighth ...</td>\n      <td>Who was brought in during the season for a fou...</td>\n      <td>{'text': ['Kara DioGuardi'], 'answer_start': [...</td>\n      <td>['Kara DioGuardi']</td>\n      <td>kara dioguardi</td>\n      <td>kara dioguardi</td>\n      <td>kara dioguardi</td>\n      <td>kara dioguardi</td>\n      <td>Kara DioGuardi</td>\n      <td>Kara DioGuardi</td>\n      <td>Kara DioGuardi</td>\n      <td>Kara DioGuardi</td>\n      <td>Kara DioGuardi</td>\n      <td>Kara DioGuardi</td>\n      <td>Kara DioGuardi</td>\n      <td>Kara DioGuardi</td>\n    </tr>\n    <tr>\n      <th>944</th>\n      <td>The first season was co-hosted by Ryan Seacres...</td>\n      <td>season</td>\n      <td>Who was the only host of American Idol after s...</td>\n      <td>Who hosted the show once season one had passed...</td>\n      <td>{'text': ['Ryan Seacrest'], 'answer_start': [34]}</td>\n      <td>['Ryan Seacrest']</td>\n      <td>brian dunkleman</td>\n      <td>brian dunkleman</td>\n      <td>ryan seacrest</td>\n      <td>ryan seacrest</td>\n      <td>Brian Dunkleman</td>\n      <td>Ryan Seacrest</td>\n      <td>Ryan Seacrest</td>\n      <td>Ryan Seacrest</td>\n      <td>Ryan Seacrest</td>\n      <td>Ryan Seacrest</td>\n      <td>Ryan Seacrest</td>\n      <td>Ryan Seacrest</td>\n    </tr>\n    <tr>\n      <th>945</th>\n      <td>Guest judges may occasionally be introduced. I...</td>\n      <td>season</td>\n      <td>Who were the guest judges in season two?</td>\n      <td>Who joined in as a guest during the second sea...</td>\n      <td>{'text': ['Lionel Richie and Robin Gibb'], 'an...</td>\n      <td>['Lionel Richie and Robin Gibb']</td>\n      <td>lionel richie and robin gibb</td>\n      <td>donna summer, quentin tarantino</td>\n      <td>lionel richie and robin gibb</td>\n      <td>lionel richie and robin gibb</td>\n      <td>Lionel Richie and Robin Gibb</td>\n      <td>Lionel Richie and Robin Gibb</td>\n      <td>Lionel Richie and Robin Gibb</td>\n      <td>Lionel Richie and Robin Gibb</td>\n      <td>Lionel Richie and Robin Gibb</td>\n      <td>Lionel Richie and Robin Gibb</td>\n      <td>Lionel Richie and Robin Gibb</td>\n      <td>Lionel Richie</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"df_words_no_cls.to_csv(\"data/error_analysis_words_no_cls_4.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:38:12.076919Z","iopub.execute_input":"2025-09-18T19:38:12.077669Z","iopub.status.idle":"2025-09-18T19:38:12.085442Z","shell.execute_reply.started":"2025-09-18T19:38:12.077643Z","shell.execute_reply":"2025-09-18T19:38:12.084673Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"markdown","source":"<div style=\"position:relative;padding:.75rem 1.25rem;margin-bottom:1rem;border:1px solid transparent;border-radius:.25rem;background-color:#dae8fc;border-color:#6c8ebf;color:#0c5460\">\n<b>1. Overall Evaluation</b> \n</div>\n\nComputes Exact Match (EM) and F1 score for both question types using the standard SQuAD metric. Saves the overall results as a DataFrame.\n\n- Source code with SQuAD [metrics](https://huggingface.co/spaces/evaluate-metric/squad_v2)","metadata":{}},{"cell_type":"code","source":"# Data obtained after answer predictions\ndf.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:38:24.465320Z","iopub.execute_input":"2025-09-18T19:38:24.465924Z","iopub.status.idle":"2025-09-18T19:38:24.480027Z","shell.execute_reply.started":"2025-09-18T19:38:24.465902Z","shell.execute_reply":"2025-09-18T19:38:24.479314Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"                                             context target_word  \\\n0  Beyoncé's first solo recording was a feature o...       album   \n1  Following the disbandment of Destiny's Child i...       album   \n2  Beyoncé's first solo recording was a feature o...       album   \n\n                                            question  \\\n0  The album, Dangerously in Love achieved what s...   \n1  After her second solo album, what other entert...   \n2  Beyonce's first album by herself was called what?   \n\n                                  annotated_question  \\\n0                   What spot did the album achieve?   \n1  After her second album, what other entertainme...   \n2                   Her first album was called what?   \n\n                                             answers      ground_truth_answer  \\\n0   {'text': ['number four'], 'answer_start': [123]}          ['number four']   \n1        {'text': ['acting'], 'answer_start': [207]}               ['acting']   \n2  {'text': ['Dangerously in Love'], 'answer_star...  ['Dangerously in Love']   \n\n   bert-base_pred_orig bert-base_pred_ambig bert-large_pred_orig  \\\n0          number four          number four          number four   \n1               acting               acting               acting   \n2  dangerously in love  dangerously in love  dangerously in love   \n\n  bert-large_pred_ambig roberta-base_pred_orig roberta-base_pred_ambig  \\\n0                                         four             number four   \n1                acting                 acting                  acting   \n2   dangerously in love    Dangerously in Love     Dangerously in Love   \n\n  roberta-large_pred_orig roberta-large_pred_ambig deberta-base_pred_orig  \\\n0                    four   atop the Billboard 200            number four   \n1                  acting                   acting                 acting   \n2     Dangerously in Love      Dangerously in Love    Dangerously in Love   \n\n  deberta-base_pred_ambig deberta-large_pred_orig deberta-large_pred_ambig  \n0                    four                    four   atop the Billboard 200  \n1                  acting                  acting                   acting  \n2     Dangerously in Love     Dangerously in Love      Dangerously in Love  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>context</th>\n      <th>target_word</th>\n      <th>question</th>\n      <th>annotated_question</th>\n      <th>answers</th>\n      <th>ground_truth_answer</th>\n      <th>bert-base_pred_orig</th>\n      <th>bert-base_pred_ambig</th>\n      <th>bert-large_pred_orig</th>\n      <th>bert-large_pred_ambig</th>\n      <th>roberta-base_pred_orig</th>\n      <th>roberta-base_pred_ambig</th>\n      <th>roberta-large_pred_orig</th>\n      <th>roberta-large_pred_ambig</th>\n      <th>deberta-base_pred_orig</th>\n      <th>deberta-base_pred_ambig</th>\n      <th>deberta-large_pred_orig</th>\n      <th>deberta-large_pred_ambig</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Beyoncé's first solo recording was a feature o...</td>\n      <td>album</td>\n      <td>The album, Dangerously in Love achieved what s...</td>\n      <td>What spot did the album achieve?</td>\n      <td>{'text': ['number four'], 'answer_start': [123]}</td>\n      <td>['number four']</td>\n      <td>number four</td>\n      <td>number four</td>\n      <td>number four</td>\n      <td></td>\n      <td>four</td>\n      <td>number four</td>\n      <td>four</td>\n      <td>atop the Billboard 200</td>\n      <td>number four</td>\n      <td>four</td>\n      <td>four</td>\n      <td>atop the Billboard 200</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Following the disbandment of Destiny's Child i...</td>\n      <td>album</td>\n      <td>After her second solo album, what other entert...</td>\n      <td>After her second album, what other entertainme...</td>\n      <td>{'text': ['acting'], 'answer_start': [207]}</td>\n      <td>['acting']</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n      <td>acting</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Beyoncé's first solo recording was a feature o...</td>\n      <td>album</td>\n      <td>Beyonce's first album by herself was called what?</td>\n      <td>Her first album was called what?</td>\n      <td>{'text': ['Dangerously in Love'], 'answer_star...</td>\n      <td>['Dangerously in Love']</td>\n      <td>dangerously in love</td>\n      <td>dangerously in love</td>\n      <td>dangerously in love</td>\n      <td>dangerously in love</td>\n      <td>Dangerously in Love</td>\n      <td>Dangerously in Love</td>\n      <td>Dangerously in Love</td>\n      <td>Dangerously in Love</td>\n      <td>Dangerously in Love</td>\n      <td>Dangerously in Love</td>\n      <td>Dangerously in Love</td>\n      <td>Dangerously in Love</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"# MASKING [CLS]\n\n# Load the metric\nmetric = evaluate.load(\"squad\")\n\n# Store the results\noverall_results_masked = []\n\nfor model_name in models.keys():\n    print(f\"\\nEvaluating {model_name}...\")\n\n    # Extract predictions for original and ambiguous questions\n    preds_orig = [\n        {'id': str(i), 'prediction_text': pred}\n        for i, pred in enumerate(df[f\"{model_name}_pred_orig\"])\n    ]\n    preds_ambig = [\n        {'id': str(i), 'prediction_text': pred}\n        for i, pred in enumerate(df[f\"{model_name}_pred_ambig\"])\n    ]\n\n    # Special token count\n    def special_token_count(preds):\n        \"\"\"Count how many times special [CLS] token or 'empty' answer was predicted.\n        Function returns number of predictions withoug real answer\"\"\"\n        return sum(\n            1 for prediction in preds \n            if str(prediction).strip().lower() in [\"\", \"cls\", \"[cls]\"])\n\n    # Number of predictions in both question types\n    cls_count_orig_masked = special_token_count(df[f\"{model_name}_pred_orig\"])\n    cls_count_ambig_masked = special_token_count(df[f\"{model_name}_pred_ambig\"])\n\n    # Ground truth answer references\n    references = [\n        {'id': str(i), 'answers': {'text': [ans], 'answer_start': [0]}}\n        for i, ans in enumerate(df['ground_truth_answer'])\n    ]\n\n    # Compute metrics\n    results_orig_masked = metric.compute(predictions=preds_orig, references=references)\n    results_ambig_masked = metric.compute(predictions=preds_ambig, references=references)\n\n    # Print results\n    print(f\"{model_name}:\")\n    print(f\"  Original Question - EM: {results_orig_masked['exact_match']:.2f}, F1: {results_orig_masked['f1']:.2f}\")\n    print(f\"  Ambiguous Question - EM: {results_ambig_masked['exact_match']:.2f}, F1: {results_ambig_masked['f1']:.2f}\")\n    print(f\"  Special token predicted: {cls_count_orig_masked} times (orig), {cls_count_ambig_masked} times (ambig)\")\n\n    # Save all results\n    overall_results_masked.append({\n        \"model\": model_name,\n        \"em_orig\": results_orig_masked['exact_match'],\n        \"f1_orig\": results_orig_masked['f1'],\n        \"em_ambig\": results_ambig_masked['exact_match'],\n        \"f1_ambig\": results_ambig_masked['f1'],\n        \"cls_count_orig\": cls_count_orig_masked,\n        \"cls_count_ambig\": cls_count_ambig_masked\n    })\n\n# Save to file\noverall_df_masked = pd.DataFrame(overall_results_masked)\noverall_df_masked.to_csv(\"data/all_models_em_f1_results_no_cls_4.csv\", sep=',', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:43:42.344282Z","iopub.execute_input":"2025-09-18T19:43:42.344578Z","iopub.status.idle":"2025-09-18T19:43:44.285758Z","shell.execute_reply.started":"2025-09-18T19:43:42.344559Z","shell.execute_reply":"2025-09-18T19:43:44.285173Z"}},"outputs":[{"name":"stdout","text":"\nEvaluating bert-base...\nbert-base:\n  Original Question - EM: 83.56, F1: 89.33\n  Ambiguous Question - EM: 65.38, F1: 74.20\n  Special token predicted: 5 times (orig), 31 times (ambig)\n\nEvaluating bert-large...\nbert-large:\n  Original Question - EM: 81.34, F1: 88.84\n  Ambiguous Question - EM: 66.80, F1: 76.87\n  Special token predicted: 5 times (orig), 21 times (ambig)\n\nEvaluating roberta-base...\nroberta-base:\n  Original Question - EM: 83.87, F1: 92.07\n  Ambiguous Question - EM: 67.83, F1: 78.13\n  Special token predicted: 9 times (orig), 24 times (ambig)\n\nEvaluating roberta-large...\nroberta-large:\n  Original Question - EM: 93.83, F1: 97.26\n  Ambiguous Question - EM: 72.81, F1: 80.94\n  Special token predicted: 4 times (orig), 14 times (ambig)\n\nEvaluating deberta-base...\ndeberta-base:\n  Original Question - EM: 97.55, F1: 98.75\n  Ambiguous Question - EM: 74.07, F1: 80.50\n  Special token predicted: 3 times (orig), 28 times (ambig)\n\nEvaluating deberta-large...\ndeberta-large:\n  Original Question - EM: 91.23, F1: 96.37\n  Ambiguous Question - EM: 73.44, F1: 81.90\n  Special token predicted: 3 times (orig), 15 times (ambig)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"## Plotting\n\n- model comparison with and without special token masking","metadata":{}},{"cell_type":"code","source":"# load the dataset\ndf = pd.read_csv(\"data/all_models_em_f1_results_3.csv\")\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:43:48.164143Z","iopub.execute_input":"2025-09-18T19:43:48.164438Z","iopub.status.idle":"2025-09-18T19:43:48.184498Z","shell.execute_reply.started":"2025-09-18T19:43:48.164415Z","shell.execute_reply":"2025-09-18T19:43:48.183754Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"           model    em_orig    f1_orig   em_ambig   f1_ambig  cls_count_orig  \\\n0      bert-base  83.162055  88.909852  61.027668  69.107880              13   \n1     bert-large  81.343874  88.841362  66.798419  76.872061               5   \n2   roberta-base  82.213439  90.053486  61.264822  70.539917              10   \n3  roberta-large  93.596838  96.959785  64.822134  71.488967               4   \n4   deberta-base  97.470356  98.675843  68.774704  74.048739               4   \n5  deberta-large  91.225296  96.366815  64.664032  72.073065               4   \n\n   cls_count_ambig  \n0              134  \n1               22  \n2               20  \n3               15  \n4              162  \n5              190  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>em_orig</th>\n      <th>f1_orig</th>\n      <th>em_ambig</th>\n      <th>f1_ambig</th>\n      <th>cls_count_orig</th>\n      <th>cls_count_ambig</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bert-base</td>\n      <td>83.162055</td>\n      <td>88.909852</td>\n      <td>61.027668</td>\n      <td>69.107880</td>\n      <td>13</td>\n      <td>134</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bert-large</td>\n      <td>81.343874</td>\n      <td>88.841362</td>\n      <td>66.798419</td>\n      <td>76.872061</td>\n      <td>5</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>roberta-base</td>\n      <td>82.213439</td>\n      <td>90.053486</td>\n      <td>61.264822</td>\n      <td>70.539917</td>\n      <td>10</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>roberta-large</td>\n      <td>93.596838</td>\n      <td>96.959785</td>\n      <td>64.822134</td>\n      <td>71.488967</td>\n      <td>4</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>deberta-base</td>\n      <td>97.470356</td>\n      <td>98.675843</td>\n      <td>68.774704</td>\n      <td>74.048739</td>\n      <td>4</td>\n      <td>162</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>deberta-large</td>\n      <td>91.225296</td>\n      <td>96.366815</td>\n      <td>64.664032</td>\n      <td>72.073065</td>\n      <td>4</td>\n      <td>190</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:44:51.566895Z","iopub.execute_input":"2025-09-18T19:44:51.567567Z","iopub.status.idle":"2025-09-18T19:44:51.572389Z","shell.execute_reply.started":"2025-09-18T19:44:51.567540Z","shell.execute_reply":"2025-09-18T19:44:51.571721Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"Index(['model', 'em_orig', 'f1_orig', 'em_ambig', 'f1_ambig', 'cls_count_orig',\n       'cls_count_ambig'],\n      dtype='object')"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"# load the dataset\ndf_masked = pd.read_csv(\"data/all_models_em_f1_results_no_cls_4.csv\")\n\ndf_masked","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:45:09.971172Z","iopub.execute_input":"2025-09-18T19:45:09.971468Z","iopub.status.idle":"2025-09-18T19:45:09.983457Z","shell.execute_reply.started":"2025-09-18T19:45:09.971447Z","shell.execute_reply":"2025-09-18T19:45:09.982849Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"           model    em_orig    f1_orig   em_ambig   f1_ambig  cls_count_orig  \\\n0      bert-base  83.557312  89.327695  65.375494  74.198342               5   \n1     bert-large  81.343874  88.841362  66.798419  76.872061               5   \n2   roberta-base  83.873518  92.070437  67.826087  78.127571               9   \n3  roberta-large  93.833992  97.260180  72.806324  80.943769               4   \n4   deberta-base  97.549407  98.745013  74.071146  80.503608               3   \n5  deberta-large  91.225296  96.366815  73.438735  81.904492               3   \n\n   cls_count_ambig  \n0               31  \n1               21  \n2               24  \n3               14  \n4               28  \n5               15  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>em_orig</th>\n      <th>f1_orig</th>\n      <th>em_ambig</th>\n      <th>f1_ambig</th>\n      <th>cls_count_orig</th>\n      <th>cls_count_ambig</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bert-base</td>\n      <td>83.557312</td>\n      <td>89.327695</td>\n      <td>65.375494</td>\n      <td>74.198342</td>\n      <td>5</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bert-large</td>\n      <td>81.343874</td>\n      <td>88.841362</td>\n      <td>66.798419</td>\n      <td>76.872061</td>\n      <td>5</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>roberta-base</td>\n      <td>83.873518</td>\n      <td>92.070437</td>\n      <td>67.826087</td>\n      <td>78.127571</td>\n      <td>9</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>roberta-large</td>\n      <td>93.833992</td>\n      <td>97.260180</td>\n      <td>72.806324</td>\n      <td>80.943769</td>\n      <td>4</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>deberta-base</td>\n      <td>97.549407</td>\n      <td>98.745013</td>\n      <td>74.071146</td>\n      <td>80.503608</td>\n      <td>3</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>deberta-large</td>\n      <td>91.225296</td>\n      <td>96.366815</td>\n      <td>73.438735</td>\n      <td>81.904492</td>\n      <td>3</td>\n      <td>15</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"df_masked.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:45:48.584914Z","iopub.execute_input":"2025-09-18T19:45:48.585424Z","iopub.status.idle":"2025-09-18T19:45:48.590326Z","shell.execute_reply.started":"2025-09-18T19:45:48.585393Z","shell.execute_reply":"2025-09-18T19:45:48.589638Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"Index(['model', 'em_orig', 'f1_orig', 'em_ambig', 'f1_ambig', 'cls_count_orig',\n       'cls_count_ambig'],\n      dtype='object')"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"# Merge datasets for comparison\ndf = df.merge(df_masked, on=\"model\", suffixes=(\"_unmasked\", \"_masked\"))\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:46:19.565517Z","iopub.execute_input":"2025-09-18T19:46:19.565786Z","iopub.status.idle":"2025-09-18T19:46:19.594763Z","shell.execute_reply.started":"2025-09-18T19:46:19.565767Z","shell.execute_reply":"2025-09-18T19:46:19.594079Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"           model  em_orig_unmasked  f1_orig_unmasked  em_ambig_unmasked  \\\n0      bert-base         83.162055         88.909852          61.027668   \n1     bert-large         81.343874         88.841362          66.798419   \n2   roberta-base         82.213439         90.053486          61.264822   \n3  roberta-large         93.596838         96.959785          64.822134   \n4   deberta-base         97.470356         98.675843          68.774704   \n5  deberta-large         91.225296         96.366815          64.664032   \n\n   f1_ambig_unmasked  cls_count_orig_unmasked  cls_count_ambig_unmasked  \\\n0          69.107880                       13                       134   \n1          76.872061                        5                        22   \n2          70.539917                       10                        20   \n3          71.488967                        4                        15   \n4          74.048739                        4                       162   \n5          72.073065                        4                       190   \n\n   em_orig_masked  f1_orig_masked  em_ambig_masked  f1_ambig_masked  \\\n0       83.557312       89.327695        65.375494        74.198342   \n1       81.343874       88.841362        66.798419        76.872061   \n2       83.873518       92.070437        67.826087        78.127571   \n3       93.833992       97.260180        72.806324        80.943769   \n4       97.549407       98.745013        74.071146        80.503608   \n5       91.225296       96.366815        73.438735        81.904492   \n\n   cls_count_orig_masked  cls_count_ambig_masked  \n0                      5                      31  \n1                      5                      21  \n2                      9                      24  \n3                      4                      14  \n4                      3                      28  \n5                      3                      15  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>em_orig_unmasked</th>\n      <th>f1_orig_unmasked</th>\n      <th>em_ambig_unmasked</th>\n      <th>f1_ambig_unmasked</th>\n      <th>cls_count_orig_unmasked</th>\n      <th>cls_count_ambig_unmasked</th>\n      <th>em_orig_masked</th>\n      <th>f1_orig_masked</th>\n      <th>em_ambig_masked</th>\n      <th>f1_ambig_masked</th>\n      <th>cls_count_orig_masked</th>\n      <th>cls_count_ambig_masked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bert-base</td>\n      <td>83.162055</td>\n      <td>88.909852</td>\n      <td>61.027668</td>\n      <td>69.107880</td>\n      <td>13</td>\n      <td>134</td>\n      <td>83.557312</td>\n      <td>89.327695</td>\n      <td>65.375494</td>\n      <td>74.198342</td>\n      <td>5</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bert-large</td>\n      <td>81.343874</td>\n      <td>88.841362</td>\n      <td>66.798419</td>\n      <td>76.872061</td>\n      <td>5</td>\n      <td>22</td>\n      <td>81.343874</td>\n      <td>88.841362</td>\n      <td>66.798419</td>\n      <td>76.872061</td>\n      <td>5</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>roberta-base</td>\n      <td>82.213439</td>\n      <td>90.053486</td>\n      <td>61.264822</td>\n      <td>70.539917</td>\n      <td>10</td>\n      <td>20</td>\n      <td>83.873518</td>\n      <td>92.070437</td>\n      <td>67.826087</td>\n      <td>78.127571</td>\n      <td>9</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>roberta-large</td>\n      <td>93.596838</td>\n      <td>96.959785</td>\n      <td>64.822134</td>\n      <td>71.488967</td>\n      <td>4</td>\n      <td>15</td>\n      <td>93.833992</td>\n      <td>97.260180</td>\n      <td>72.806324</td>\n      <td>80.943769</td>\n      <td>4</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>deberta-base</td>\n      <td>97.470356</td>\n      <td>98.675843</td>\n      <td>68.774704</td>\n      <td>74.048739</td>\n      <td>4</td>\n      <td>162</td>\n      <td>97.549407</td>\n      <td>98.745013</td>\n      <td>74.071146</td>\n      <td>80.503608</td>\n      <td>3</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>deberta-large</td>\n      <td>91.225296</td>\n      <td>96.366815</td>\n      <td>64.664032</td>\n      <td>72.073065</td>\n      <td>4</td>\n      <td>190</td>\n      <td>91.225296</td>\n      <td>96.366815</td>\n      <td>73.438735</td>\n      <td>81.904492</td>\n      <td>3</td>\n      <td>15</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:46:30.814681Z","iopub.execute_input":"2025-09-18T19:46:30.815282Z","iopub.status.idle":"2025-09-18T19:46:30.820131Z","shell.execute_reply.started":"2025-09-18T19:46:30.815255Z","shell.execute_reply":"2025-09-18T19:46:30.819428Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"Index(['model', 'em_orig_unmasked', 'f1_orig_unmasked', 'em_ambig_unmasked',\n       'f1_ambig_unmasked', 'cls_count_orig_unmasked',\n       'cls_count_ambig_unmasked', 'em_orig_masked', 'f1_orig_masked',\n       'em_ambig_masked', 'f1_ambig_masked', 'cls_count_orig_masked',\n       'cls_count_ambig_masked'],\n      dtype='object')"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"# Count F1 difference between masked and unmasked tokens\ndf[\"delta_f1_orig\"]  = df[\"f1_orig_masked\"]  - df[\"f1_orig_unmasked\"]\ndf[\"delta_f1_ambig\"] = df[\"f1_ambig_masked\"] - df[\"f1_ambig_unmasked\"]\n\n# Count special token prediction difference between masked and unmasked tokens\ndf[\"delta_cls_orig\"]  = df[\"cls_count_orig_masked\"]  - df[\"cls_count_orig_unmasked\"]\ndf[\"delta_cls_ambig\"] = df[\"cls_count_ambig_masked\"] - df[\"cls_count_ambig_unmasked\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:46:36.238161Z","iopub.execute_input":"2025-09-18T19:46:36.239119Z","iopub.status.idle":"2025-09-18T19:46:36.246196Z","shell.execute_reply.started":"2025-09-18T19:46:36.239086Z","shell.execute_reply":"2025-09-18T19:46:36.245547Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:46:40.901088Z","iopub.execute_input":"2025-09-18T19:46:40.901849Z","iopub.status.idle":"2025-09-18T19:46:40.915233Z","shell.execute_reply.started":"2025-09-18T19:46:40.901821Z","shell.execute_reply":"2025-09-18T19:46:40.914436Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"           model  em_orig_unmasked  f1_orig_unmasked  em_ambig_unmasked  \\\n0      bert-base         83.162055         88.909852          61.027668   \n1     bert-large         81.343874         88.841362          66.798419   \n2   roberta-base         82.213439         90.053486          61.264822   \n3  roberta-large         93.596838         96.959785          64.822134   \n4   deberta-base         97.470356         98.675843          68.774704   \n5  deberta-large         91.225296         96.366815          64.664032   \n\n   f1_ambig_unmasked  cls_count_orig_unmasked  cls_count_ambig_unmasked  \\\n0          69.107880                       13                       134   \n1          76.872061                        5                        22   \n2          70.539917                       10                        20   \n3          71.488967                        4                        15   \n4          74.048739                        4                       162   \n5          72.073065                        4                       190   \n\n   em_orig_masked  f1_orig_masked  em_ambig_masked  f1_ambig_masked  \\\n0       83.557312       89.327695        65.375494        74.198342   \n1       81.343874       88.841362        66.798419        76.872061   \n2       83.873518       92.070437        67.826087        78.127571   \n3       93.833992       97.260180        72.806324        80.943769   \n4       97.549407       98.745013        74.071146        80.503608   \n5       91.225296       96.366815        73.438735        81.904492   \n\n   cls_count_orig_masked  cls_count_ambig_masked  delta_f1_orig  \\\n0                      5                      31       0.417843   \n1                      5                      21       0.000000   \n2                      9                      24       2.016951   \n3                      4                      14       0.300395   \n4                      3                      28       0.069170   \n5                      3                      15       0.000000   \n\n   delta_f1_ambig  delta_cls_orig  delta_cls_ambig  \n0        5.090461              -8             -103  \n1        0.000000               0               -1  \n2        7.587654              -1                4  \n3        9.454802               0               -1  \n4        6.454869              -1             -134  \n5        9.831427              -1             -175  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>em_orig_unmasked</th>\n      <th>f1_orig_unmasked</th>\n      <th>em_ambig_unmasked</th>\n      <th>f1_ambig_unmasked</th>\n      <th>cls_count_orig_unmasked</th>\n      <th>cls_count_ambig_unmasked</th>\n      <th>em_orig_masked</th>\n      <th>f1_orig_masked</th>\n      <th>em_ambig_masked</th>\n      <th>f1_ambig_masked</th>\n      <th>cls_count_orig_masked</th>\n      <th>cls_count_ambig_masked</th>\n      <th>delta_f1_orig</th>\n      <th>delta_f1_ambig</th>\n      <th>delta_cls_orig</th>\n      <th>delta_cls_ambig</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bert-base</td>\n      <td>83.162055</td>\n      <td>88.909852</td>\n      <td>61.027668</td>\n      <td>69.107880</td>\n      <td>13</td>\n      <td>134</td>\n      <td>83.557312</td>\n      <td>89.327695</td>\n      <td>65.375494</td>\n      <td>74.198342</td>\n      <td>5</td>\n      <td>31</td>\n      <td>0.417843</td>\n      <td>5.090461</td>\n      <td>-8</td>\n      <td>-103</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bert-large</td>\n      <td>81.343874</td>\n      <td>88.841362</td>\n      <td>66.798419</td>\n      <td>76.872061</td>\n      <td>5</td>\n      <td>22</td>\n      <td>81.343874</td>\n      <td>88.841362</td>\n      <td>66.798419</td>\n      <td>76.872061</td>\n      <td>5</td>\n      <td>21</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>roberta-base</td>\n      <td>82.213439</td>\n      <td>90.053486</td>\n      <td>61.264822</td>\n      <td>70.539917</td>\n      <td>10</td>\n      <td>20</td>\n      <td>83.873518</td>\n      <td>92.070437</td>\n      <td>67.826087</td>\n      <td>78.127571</td>\n      <td>9</td>\n      <td>24</td>\n      <td>2.016951</td>\n      <td>7.587654</td>\n      <td>-1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>roberta-large</td>\n      <td>93.596838</td>\n      <td>96.959785</td>\n      <td>64.822134</td>\n      <td>71.488967</td>\n      <td>4</td>\n      <td>15</td>\n      <td>93.833992</td>\n      <td>97.260180</td>\n      <td>72.806324</td>\n      <td>80.943769</td>\n      <td>4</td>\n      <td>14</td>\n      <td>0.300395</td>\n      <td>9.454802</td>\n      <td>0</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>deberta-base</td>\n      <td>97.470356</td>\n      <td>98.675843</td>\n      <td>68.774704</td>\n      <td>74.048739</td>\n      <td>4</td>\n      <td>162</td>\n      <td>97.549407</td>\n      <td>98.745013</td>\n      <td>74.071146</td>\n      <td>80.503608</td>\n      <td>3</td>\n      <td>28</td>\n      <td>0.069170</td>\n      <td>6.454869</td>\n      <td>-1</td>\n      <td>-134</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>deberta-large</td>\n      <td>91.225296</td>\n      <td>96.366815</td>\n      <td>64.664032</td>\n      <td>72.073065</td>\n      <td>4</td>\n      <td>190</td>\n      <td>91.225296</td>\n      <td>96.366815</td>\n      <td>73.438735</td>\n      <td>81.904492</td>\n      <td>3</td>\n      <td>15</td>\n      <td>0.000000</td>\n      <td>9.831427</td>\n      <td>-1</td>\n      <td>-175</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"df.to_csv(\"data/df_masked_unmasked_cls_compare_4.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T19:47:17.761812Z","iopub.execute_input":"2025-09-18T19:47:17.762100Z","iopub.status.idle":"2025-09-18T19:47:17.767430Z","shell.execute_reply.started":"2025-09-18T19:47:17.762078Z","shell.execute_reply":"2025-09-18T19:47:17.766754Z"}},"outputs":[],"execution_count":45}]}